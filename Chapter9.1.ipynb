{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "049c9a96",
   "metadata": {},
   "source": [
    "# 텍스트를 위한 인공 신경망"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c92eb69",
   "metadata": {},
   "source": [
    "## 순차 데이터와 순환 신경망"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12433ae0",
   "metadata": {},
   "source": [
    "### 순차 데이터"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d664e8e",
   "metadata": {},
   "source": [
    "순차 데이터(sequential data)\n",
    "- 텍스트나 시계열 데이터(time series data)와 같이 순서에 의미가 있는 데이터\n",
    "\n",
    "- 순서를 유지하며 신경망에 주입해야 함\n",
    "- 순차 데이터를 다룰 때는 이전에 입력한 데이터를 기억하는 기능이 필요\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a63c805",
   "metadata": {},
   "source": [
    "피드 포워드 신경망(feedforward neural network)\n",
    "- 입력 데이터의 흐름이 앞으로만 전달되는 신경망\n",
    "- ex) 완전 연결 신경망, 합성곱 신경망 등\n",
    "\n",
    "- 완전 연결 신경망이나 합성곱 신경망은 이런 기억 장치가 없음 \n",
    "- - 하나의 샘플(또는 배치)을 사용하여 정방향 계산을 수행하고 나면 그 샘플은 버려지고 다음 샘플을 처리할 때 재사용 하지 않음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "358e0c3a",
   "metadata": {},
   "source": [
    "### 순환 신경망"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dfac9c6",
   "metadata": {},
   "source": [
    "순환 신경망(recurrent neural network)\n",
    "- 신경망이 이전에 처리한 샘플을 다음 샘플을 처리하는데 재사용하기 위해서는 데이터 흐름이 앞으로만 전달되면 안됨\n",
    "- 다음 샘플을 위해서 이전 데이터가 신경망 층에 순횐될 필요가 있음\n",
    "\n",
    "- 일반적인 완전 연결 신경망과 비슷\n",
    "- 완전 연결 신경망 + 이전 데이터의 처리 흐름을 순환하는 고리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e364094b",
   "metadata": {},
   "source": [
    "- 뉴런의 출력이 다시 자기 자신으로 전달됨\n",
    "\n",
    "- 어떤 샘플을 처리할 때 바로 이전에 사용했던 데이터를 재사용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01cc2eb3",
   "metadata": {},
   "source": [
    "타임스텝(timestep)\n",
    "- 샘플을 처리하는 한 단계"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39a6aa3",
   "metadata": {},
   "source": [
    "- 순환 신경망은 이전 타임스텝의 샘플을 기억하지만 타임스텝이 오래될수록 순환되는 정보는 희미해짐"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f430266a",
   "metadata": {},
   "source": [
    "셀(cell)\n",
    "- 층\n",
    "\n",
    "- 한 셀에는 여려 개의 뉴런이 있지만 완전 연결 신경망과 달리 뉴런을 모두 표시하지 않고 하나의 셀로 층을 표현\n",
    "- 셀의 출력 >  은닉상태(hidden state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd6dd787",
   "metadata": {},
   "source": [
    "- 신경망의 구조마다 조금씩 부르는 이름이 다를 수 있음\n",
    "\n",
    "- 기본 구조는 같음\n",
    "- 입력에 어떤 가중치를 곱하고 활성화 함수를 통과시켜 다음 층으로 보낸다\n",
    "- 달라지는 것은 층의 출력(은닉상태)을 다음 타입 스텝에 재사용 하는 것"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4063bbbc",
   "metadata": {},
   "source": [
    "- 일반적으로 은닉승의 활성화 함수로는 하이터볼릭 탄젠트(hyperbolic tangent) 함ㅁ수인 tang사 많이 사용\n",
    "\n",
    "- S자 모양을 띠기 때문에 시그모이드 함수(0~1)라고 부르기도 함\n",
    "- tanh 함수는 -1 ~ 1 사이의 범위를 가짐"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d1f9c7c",
   "metadata": {},
   "source": [
    "- 다른 신경망과 마찬가지로 순환 신경망 그림에도 번거로움을 피하기 위해 활성화 함수를 표시하지 않는 경우가 있음\n",
    "\n",
    "- 하지만 순환 신경망에도 활성화 함수가 반드시 필요!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb45cbe",
   "metadata": {},
   "source": [
    "- 합성곱 신경망과 같은 피드포워드 신경망에서 뉴런은 입력과 가중치를 곱한다\n",
    "- 순환 신경망에서도 동일\n",
    "\n",
    "- 다만 순환 신경망의 뉴런은 가중치가 하나 더 있다\n",
    "- - 바로 전 타입스텝의 은닉 상태에 곱해지는 가중치\n",
    "- 셀은 입력과 이전 타임스텝의 은닉 상태를 사용하여 현재 타임스텝의 은닉 상태를 만든다"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
